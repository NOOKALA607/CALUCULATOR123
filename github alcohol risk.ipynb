{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# PREDICTING THE RISK OF ALCOHOL FOR 7 TARGETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['NAIVE', GaussianNB(priors=None, var_smoothing=1e-09)], ['SVM', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)], ['DECISION', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')], ['RAND', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)], ['KNN', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')]]\n",
      "accuracy without scaler NAIVE 0.18376256812229935\n",
      "accuracy without scaler SVM 0.19880160815335074\n",
      "accuracy without scaler DECISION 0.15689560504477346\n",
      "accuracy without scaler RAND 0.187033491597872\n",
      "accuracy without scaler KNN 0.14571587401111794\n",
      "accuracy with scaler KNN 0.15931926130352278\n",
      "accuracy with scaler NAIVE 0.18376256812229935\n",
      "accuracy with scaler SVM 0.21243407833371947\n",
      "accuracy with scaler RAND 0.17357611696725178\n",
      "accuracy with scaler DECISION 0.1554313007655162\n"
     ]
    }
   ],
   "source": [
    "#IMPORT THE DATASET\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.read_csv(\"E:\\DSTUTORIALS\\Drug-consumers project\\durg alcohol.csv\")\n",
    "#print(df)\n",
    "\n",
    "#CONVERT ALL THE LABELED DATA INTO NUMERICAL DATA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "m=LabelEncoder()\n",
    "df[\"Gender\"]=m.fit_transform(df[\"Gender\"])\n",
    "df[\"Country\"]=m.fit_transform(df[\"Country\"])\n",
    "df[\"Ethnicity\"]=m.fit_transform(df[\"Ethnicity\"])\n",
    "df[\"Alcohol\"]=m.fit_transform(df[\"Alcohol\"])\n",
    "df[\"Age\"]=m.fit_transform(df[\"Age\"])\n",
    "df[\"Impulsive\"]=m.fit_transform(df[\"Impulsive\"])\n",
    "\n",
    "#BELOW ARE DIFFFERENT TARGETS FOR SAME DATASET\n",
    "n=df[\"Nscore\"]\n",
    "e=df[\"Escore\"]\n",
    "o=df[\"Oscore\"]\n",
    "a=df[\"Ascore\"]\n",
    "c=df[\"Cscore\"]\n",
    "i=df[\"Impulsive\"]\n",
    "ss=df[\"SS\"]\n",
    "x=df.drop([\"Nscore\",\"Escore\",\"Oscore\",\"Ascore\",\"Cscore\",\"Impulsive\",\"SS\"],axis=1)\n",
    "#SPLITTING THE DATA INTO TRAINING AND TESTING DATA\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,n,test_size=0.3)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,e,test_size=0.3)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,o,test_size=0.3)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,a,test_size=0.3)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,c,test_size=0.3)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,i,test_size=0.3)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,ss,test_size=0.3)\n",
    "# I COMPARED THOSE ALGORITHMS FOR FINDING THE ACCURACY WHICH GIVES BETTER ACCURACY\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "algname=[]\n",
    "svmname=[\"SVM\",SVC()]\n",
    "decname=[\"DECISION\",DecisionTreeClassifier()]\n",
    "randname=[\"RAND\",RandomForestClassifier(n_estimators=10)]\n",
    "naviename=[\"NAIVE\",GaussianNB()]\n",
    "neighbname=[\"KNN\",KNeighborsClassifier()]\n",
    "algname.append(naviename)\n",
    "algname.append(svmname)\n",
    "algname.append(decname)\n",
    "algname.append(randname)\n",
    "algname.append(neighbname)\n",
    "print(algname)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "names=[]\n",
    "results=[]\n",
    "for name, models in algname:\n",
    "    kfold=KFold(n_splits=30)\n",
    "    c_results=cross_val_score(models,x_train,y_train,cv=10,scoring=\"accuracy\")\n",
    "    names.append(name)\n",
    "    results.append(c_results.mean())\n",
    "    print(\"accuracy without scaler\",name,c_results.mean())\n",
    "\n",
    "#BY THE CROSS VALIDATION I GOT VERY LESS ACCURACY TO IMPROVE THE ACCURACY I STANDARDISE THE INPUT DATA WITH STANDARDSCALER   \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "pipelines=[]\n",
    "pipelines.append((\"KNN\",Pipeline([(\"scaler\",StandardScaler()),(\"KNN\",KNeighborsClassifier())])))\n",
    "pipelines.append((\"NAIVE\",Pipeline([(\"scaler\",StandardScaler()),(\"naive\",GaussianNB())])))\n",
    "pipelines.append((\"SVM\",Pipeline([(\"scaler\",StandardScaler()),(\"SVC\",SVC())])))\n",
    "pipelines.append((\"RAND\",Pipeline([(\"scaler\",StandardScaler()),(\"Rand\",RandomForestClassifier())])))\n",
    "pipelines.append((\"DECISION\",Pipeline([(\"scaler\",StandardScaler()),(\"DECISION\",DecisionTreeClassifier())])))\n",
    "names=[]\n",
    "results=[]\n",
    "for name, model in pipelines:\n",
    "    kfold=KFold(n_splits=30)\n",
    "    c_results=cross_val_score(model,x_train,y_train,cv=10,scoring=\"accuracy\")\n",
    "    names.append(name)\n",
    "    results.append(c_results.mean())\n",
    "    print(\"accuracy with scaler\",name,c_results.mean())\n",
    " \n",
    " #IN THIS WAY I REPEATED THIS PROCESS TO DEFINE EACH TARGET VARIABLE\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211\n",
      " 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211\n",
      " 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211\n",
      " 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211\n",
      " 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211\n",
      " 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211\n",
      " 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211\n",
      " 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211\n",
      " 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211\n",
      " 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211\n",
      " 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211\n",
      " 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211\n",
      " 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211\n",
      " 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211\n",
      " 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211\n",
      " 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211\n",
      " 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211\n",
      " 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211\n",
      " 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211\n",
      " 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211\n",
      " 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211\n",
      " 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211\n",
      " 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211\n",
      " 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211\n",
      " 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211\n",
      " 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211\n",
      " 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211\n",
      " 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211\n",
      " 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211\n",
      " 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211\n",
      " 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211 211\n",
      " 211 211 211 211 211 211 211 211]\n",
      "0.2226148409893993\n",
      "[[  0   0   0   0   0   0  22   0   0   0]\n",
      " [  0   0   0   0   0   0  28   0   0   0]\n",
      " [  0   0   0   0   0   0  24   0   0   0]\n",
      " [  0   0   0   0   0   0  34   0   0   0]\n",
      " [  0   0   0   0   0   0  53   0   0   0]\n",
      " [  0   0   0   0   0   0  56   0   0   0]\n",
      " [  0   0   0   0   0   0 126   0   0   0]\n",
      " [  0   0   0   0   0   0  69   0   0   0]\n",
      " [  0   0   0   0   0   0  76   0   0   0]\n",
      " [  0   0   0   0   0   0  78   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          71       0.00      0.00      0.00        22\n",
      "          87       0.00      0.00      0.00        28\n",
      "         103       0.00      0.00      0.00        24\n",
      "         132       0.00      0.00      0.00        34\n",
      "         169       0.00      0.00      0.00        53\n",
      "         210       0.00      0.00      0.00        56\n",
      "         211       0.22      1.00      0.36       126\n",
      "         219       0.00      0.00      0.00        69\n",
      "         223       0.00      0.00      0.00        76\n",
      "         249       0.00      0.00      0.00        78\n",
      "\n",
      "    accuracy                           0.22       566\n",
      "   macro avg       0.02      0.10      0.04       566\n",
      "weighted avg       0.05      0.22      0.08       566\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc=SVC(kernel=\"linear\",C=2)\n",
    "model=svc.fit(x_train,y_train)\n",
    "y_predict1=model.predict(x_test)\n",
    "print(y_predict1)\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "#ACCURACY SCORE FINDING NUMBER OF POSITIVES MORE THAN NEGATIVES\n",
    "\n",
    "ac=accuracy_score(y_test,y_predict1)\n",
    "print(ac)\n",
    "#TO COMPARE ACTUAL AND PREDICTED VALUES\n",
    "cm=confusion_matrix(y_test,y_predict1)\n",
    "print(cm)\n",
    "\n",
    "#TO GIVE F1- SCORE,PRECISIO,RECALL\n",
    "cr=classification_report(y_test,y_predict1)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['NAIVE', GaussianNB(priors=None, var_smoothing=1e-09)], ['SVM', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)], ['DECISION', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')], ['RAND', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)], ['KNN', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')]]\n",
      "accuracy without scaler NAIVE 0.021099579564122853\n",
      "accuracy without scaler SVM 0.12792484439235893\n",
      "accuracy without scaler DECISION 0.10136510682641789\n",
      "accuracy without scaler RAND 0.10644688268912392\n",
      "accuracy without scaler KNN 0.11090522820994231\n",
      "accuracy with scaler KNN 0.10753925647482517\n",
      "accuracy with scaler NAIVE 0.021099579564122853\n",
      "accuracy with scaler SVM 0.13333078451684693\n",
      "accuracy with scaler RAND 0.11404243509813965\n",
      "accuracy with scaler DECISION 0.10220270081138028\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"E:\\DSTUTORIALS\\Drug-consumers project\\durg alcohol.csv\")\n",
    "#print(df)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "m=LabelEncoder()\n",
    "df[\"Gender\"]=m.fit_transform(df[\"Gender\"])\n",
    "df[\"Country\"]=m.fit_transform(df[\"Country\"])\n",
    "df[\"Ethnicity\"]=m.fit_transform(df[\"Ethnicity\"])\n",
    "df[\"Alcohol\"]=m.fit_transform(df[\"Alcohol\"])\n",
    "df[\"Age\"]=m.fit_transform(df[\"Age\"])\n",
    "df[\"Impulsive\"]=m.fit_transform(df[\"Impulsive\"])\n",
    "\n",
    "\n",
    "n=df[\"Nscore\"]\n",
    "e=df[\"Escore\"]\n",
    "o=df[\"Oscore\"]\n",
    "a=df[\"Ascore\"]\n",
    "c=df[\"Cscore\"]\n",
    "i=df[\"Impulsive\"]\n",
    "ss=df[\"SS\"]\n",
    "x=df.drop([\"Nscore\",\"Escore\",\"Oscore\",\"Ascore\",\"Cscore\",\"Impulsive\",\"SS\"],axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,n,test_size=0.3)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,e,test_size=0.3)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,o,test_size=0.3)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,a,test_size=0.3)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,c,test_size=0.3)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,i,test_size=0.3)\n",
    "#x_train,x_test,y_train,y_test=train_test_split(x,ss,test_size=0.3)\n",
    "\n",
    "'''\n",
    "x=[n,e,o,a,c,i,ss]\n",
    "for i in f:\n",
    "    x_train,x_test,y_train,y_test=train_test_split(x,i,test_size=0.3)\n",
    "'''\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "algname=[]\n",
    "svmname=[\"SVM\",SVC()]\n",
    "decname=[\"DECISION\",DecisionTreeClassifier()]\n",
    "randname=[\"RAND\",RandomForestClassifier(n_estimators=10)]\n",
    "naviename=[\"NAIVE\",GaussianNB()]\n",
    "neighbname=[\"KNN\",KNeighborsClassifier()]\n",
    "algname.append(naviename)\n",
    "algname.append(svmname)\n",
    "algname.append(decname)\n",
    "algname.append(randname)\n",
    "algname.append(neighbname)\n",
    "print(algname)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "names=[]\n",
    "results=[]\n",
    "for name, models in algname:\n",
    "    kfold=KFold(n_splits=30)\n",
    "    c_results=cross_val_score(models,x_train,y_train,cv=10,scoring=\"accuracy\")\n",
    "    names.append(name)\n",
    "    results.append(c_results.mean())\n",
    "    print(\"accuracy without scaler\",name,c_results.mean())\n",
    "\n",
    "    \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "pipelines=[]\n",
    "pipelines.append((\"KNN\",Pipeline([(\"scaler\",StandardScaler()),(\"KNN\",KNeighborsClassifier())])))\n",
    "pipelines.append((\"NAIVE\",Pipeline([(\"scaler\",StandardScaler()),(\"naive\",GaussianNB())])))\n",
    "pipelines.append((\"SVM\",Pipeline([(\"scaler\",StandardScaler()),(\"SVC\",SVC())])))\n",
    "pipelines.append((\"RAND\",Pipeline([(\"scaler\",StandardScaler()),(\"Rand\",RandomForestClassifier())])))\n",
    "pipelines.append((\"DECISION\",Pipeline([(\"scaler\",StandardScaler()),(\"DECISION\",DecisionTreeClassifier())])))\n",
    "names=[]\n",
    "results=[]\n",
    "for name, model in pipelines:\n",
    "    kfold=KFold(n_splits=30)\n",
    "    c_results=cross_val_score(model,x_train,y_train,cv=10,scoring=\"accuracy\")\n",
    "    names.append(name)\n",
    "    results.append(c_results.mean())\n",
    "    print(\"accuracy with scaler\",name,c_results.mean())\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 2 3 3 1 3 3 2 2 1 1 3 2 3 3 2 3 3 3 2 3 3 3 2 3 2 2 3 2 3 3 3 3 1 3 3\n",
      " 3 2 2 3 3 3 3 2 3 2 2 3 1 3 3 3 3 2 1 1 3 3 2 1 2 1 3 3 2 2 1 1 3 2 3 3 1\n",
      " 2 2 3 3 3 2 3 3 3 3 2 2 2 3 2 3 3 2 2 1 3 3 3 2 3 2 2 2 2 2 3 3 3 2 2 1 3\n",
      " 3 3 3 3 2 1 2 3 3 2 3 3 3 3 3 2 1 3 1 2 3 2 2 2 2 1 1 3 3 2 3 3 1 3 1 2 3\n",
      " 1 3 1 2 2 3 3 3 2 2 3 2 2 3 3 3 3 3 3 3 2 3 3 3 3 2 2 3 2 1 1 1 2 3 2 3 3\n",
      " 2 1 2 3 3 2 2 3 2 2 1 3 2 3 2 3 2 2 2 1 1 2 2 2 3 2 3 1 2 3 3 2 2 1 3 3 3\n",
      " 2 2 3 3 2 3 2 2 1 2 3 3 1 3 1 2 3 3 3 2 2 2 2 2 2 2 2 1 2 2 1 1 3 2 3 3 1\n",
      " 2 3 3 3 1 3 3 3 3 2 3 3 2 3 2 2 3 3 2 3 2 2 3 2 2 2 1 3 2 2 1 2 3 3 3 2 2\n",
      " 3 3 3 2 2 3 3 1 2 2 2 1 3 1 3 3 2 2 3 3 1 3 2 2 3 3 2 1 2 2 2 1 2 3 2 3 2\n",
      " 2 3 2 2 2 2 2 3 2 3 3 3 1 2 2 2 3 1 2 3 3 3 2 2 3 1 3 1 3 3 3 1 3 1 3 3 3\n",
      " 2 3 2 2 3 2 2 1 3 1 3 2 2 2 3 2 2 3 2 1 3 3 2 3 2 1 3 3 1 3 3 3 2 2 2 3 2\n",
      " 3 1 3 3 3 3 2 2 3 3 3 3 2 1 3 3 3 3 1 1 3 3 3 3 3 1 2 2 2 2 3 2 2 3 2 3 3\n",
      " 2 3 1 3 2 2 3 2 2 3 2 2 1 3 3 2 1 2 2 3 2 3 2 3 3 3 2 3 3 2 3 1 3 3 2 1 1\n",
      " 3 3 1 1 2 2 2 3 2 3 2 3 3 3 2 3 3 3 1 3 2 2 3 2 3 3 3 2 1 2 3 2 3 1 1 2 1\n",
      " 2 2 1 3 2 3 3 2 3 2 3 2 3 3 2 2 2 2 1 2 3 2 2 1 3 1 1 2 3 3 3 3 1 3 1 2 2\n",
      " 3 3 3 3 3 3 2 1 2 2 2]\n",
      "0.15547703180212014\n",
      "[[ 0  1  1  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 18 20 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 12 29 26  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  9 31 41  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  5 23 25  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  3 14 32  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  6 14 18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  5 19 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  5  5  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  2  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  4 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  5  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  3  3  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  6 18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  5 11  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  3 16 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  6 14 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.21      0.37      0.27        49\n",
      "           2       0.13      0.43      0.20        67\n",
      "           3       0.16      0.51      0.24        81\n",
      "           4       0.00      0.00      0.00        53\n",
      "           5       0.00      0.00      0.00        49\n",
      "           6       0.00      0.00      0.00        38\n",
      "           7       0.00      0.00      0.00        38\n",
      "           8       0.00      0.00      0.00        18\n",
      "           9       0.00      0.00      0.00         1\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         1\n",
      "          13       0.00      0.00      0.00        11\n",
      "          14       0.00      0.00      0.00        18\n",
      "          15       0.00      0.00      0.00        15\n",
      "          16       0.00      0.00      0.00        13\n",
      "          17       0.00      0.00      0.00        25\n",
      "          18       0.00      0.00      0.00        20\n",
      "          19       0.00      0.00      0.00        30\n",
      "          20       0.00      0.00      0.00        34\n",
      "\n",
      "    accuracy                           0.16       566\n",
      "   macro avg       0.03      0.07      0.04       566\n",
      "weighted avg       0.06      0.16      0.08       566\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc=SVC(kernel=\"linear\",C=2)\n",
    "model=svc.fit(x_train,y_train)\n",
    "y_predict1=model.predict(x_test)\n",
    "print(y_predict1)\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "\n",
    "\n",
    "ac=accuracy_score(y_test,y_predict1)\n",
    "print(ac)\n",
    "\n",
    "cm=confusion_matrix(y_test,y_predict1)\n",
    "print(cm)\n",
    "\n",
    "cr=classification_report(y_test,y_predict1)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['NAIVE', GaussianNB(priors=None, var_smoothing=1e-09)], ['SVM', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)], ['DECISION', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')], ['RAND', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)], ['KNN', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')]]\n",
      "accuracy without scaler NAIVE 0.005053147915512135\n",
      "accuracy without scaler SVM 0.06340959711767924\n",
      "accuracy without scaler DECISION 0.04858664147665391\n",
      "accuracy without scaler RAND 0.04813355895508499\n",
      "accuracy without scaler KNN 0.037319676083679136\n",
      "accuracy with scaler KNN 0.04221753609385073\n",
      "accuracy with scaler NAIVE 0.005053147915512135\n",
      "accuracy with scaler SVM 0.058220270688493315\n",
      "accuracy with scaler RAND 0.047546010870661966\n",
      "accuracy with scaler DECISION 0.04843937550149704\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"E:\\DSTUTORIALS\\Drug-consumers project\\durg alcohol.csv\")\n",
    "#print(df)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "m=LabelEncoder()\n",
    "df[\"Gender\"]=m.fit_transform(df[\"Gender\"])\n",
    "df[\"Country\"]=m.fit_transform(df[\"Country\"])\n",
    "df[\"Ethnicity\"]=m.fit_transform(df[\"Ethnicity\"])\n",
    "df[\"Alcohol\"]=m.fit_transform(df[\"Alcohol\"])\n",
    "df[\"Age\"]=m.fit_transform(df[\"Age\"])\n",
    "df[\"Impulsive\"]=m.fit_transform(df[\"Impulsive\"])\n",
    "\n",
    "\n",
    "n=df[\"Nscore\"]\n",
    "e=df[\"Escore\"]\n",
    "o=df[\"Oscore\"]\n",
    "a=df[\"Ascore\"]\n",
    "c=df[\"Cscore\"]\n",
    "i=df[\"Impulsive\"]\n",
    "ss=df[\"SS\"]\n",
    "x=df.drop([\"Nscore\",\"Escore\",\"Oscore\",\"Ascore\",\"Cscore\",\"Impulsive\",\"SS\"],axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,n,test_size=0.3)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,e,test_size=0.3)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,o,test_size=0.3)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,a,test_size=0.3)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,c,test_size=0.3)\n",
    "#x_train,x_test,y_train,y_test=train_test_split(x,i,test_size=0.3)\n",
    "#x_train,x_test,y_train,y_test=train_test_split(x,ss,test_size=0.3)\n",
    "\n",
    "'''\n",
    "x=[n,e,o,a,c,i,ss]\n",
    "for i in f:\n",
    "    x_train,x_test,y_train,y_test=train_test_split(x,i,test_size=0.3)\n",
    "'''\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "algname=[]\n",
    "svmname=[\"SVM\",SVC()]\n",
    "decname=[\"DECISION\",DecisionTreeClassifier()]\n",
    "randname=[\"RAND\",RandomForestClassifier(n_estimators=10)]\n",
    "naviename=[\"NAIVE\",GaussianNB()]\n",
    "neighbname=[\"KNN\",KNeighborsClassifier()]\n",
    "algname.append(naviename)\n",
    "algname.append(svmname)\n",
    "algname.append(decname)\n",
    "algname.append(randname)\n",
    "algname.append(neighbname)\n",
    "print(algname)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "names=[]\n",
    "results=[]\n",
    "for name, models in algname:\n",
    "    kfold=KFold(n_splits=30)\n",
    "    c_results=cross_val_score(models,x_train,y_train,cv=10,scoring=\"accuracy\")\n",
    "    names.append(name)\n",
    "    results.append(c_results.mean())\n",
    "    print(\"accuracy without scaler\",name,c_results.mean())\n",
    "\n",
    "    \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "pipelines=[]\n",
    "pipelines.append((\"KNN\",Pipeline([(\"scaler\",StandardScaler()),(\"KNN\",KNeighborsClassifier())])))\n",
    "pipelines.append((\"NAIVE\",Pipeline([(\"scaler\",StandardScaler()),(\"naive\",GaussianNB())])))\n",
    "pipelines.append((\"SVM\",Pipeline([(\"scaler\",StandardScaler()),(\"SVC\",SVC())])))\n",
    "pipelines.append((\"RAND\",Pipeline([(\"scaler\",StandardScaler()),(\"Rand\",RandomForestClassifier())])))\n",
    "pipelines.append((\"DECISION\",Pipeline([(\"scaler\",StandardScaler()),(\"DECISION\",DecisionTreeClassifier())])))\n",
    "names=[]\n",
    "results=[]\n",
    "for name, model in pipelines:\n",
    "    kfold=KFold(n_splits=30)\n",
    "    c_results=cross_val_score(model,x_train,y_train,cv=10,scoring=\"accuracy\")\n",
    "    names.append(name)\n",
    "    results.append(c_results.mean())\n",
    "    print(\"accuracy with scaler\",name,c_results.mean())\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46 46 37 47 37 37 46 46 45 37 40 37 46 39 40 37 46 46 46 46 37 47 40 46\n",
      " 46 37 46 44 47 46 46 41 40 46 40 39 37 37 46 39 37 46 37 46 46 46 37 46\n",
      " 46 46 46 46 46 44 41 37 46 37 40 47 45 44 46 44 46 46 46 46 37 47 46 44\n",
      " 46 45 45 44 46 40 45 46 39 46 40 45 40 46 46 46 37 41 46 46 44 41 46 44\n",
      " 46 40 45 44 45 44 46 46 44 46 40 37 41 44 37 47 37 46 44 45 46 37 40 46\n",
      " 44 37 40 46 40 41 40 46 39 45 47 37 40 46 46 40 46 46 39 47 41 46 37 46\n",
      " 37 47 46 41 47 44 37 37 47 46 46 45 40 46 40 37 46 46 45 47 46 46 45 37\n",
      " 45 37 46 47 44 40 46 44 41 45 37 46 46 41 45 46 39 45 47 46 47 40 46 46\n",
      " 47 44 46 37 41 37 39 44 37 40 41 47 37 47 40 46 46 44 46 37 46 46 46 41\n",
      " 45 46 46 44 41 46 37 40 45 46 37 46 46 37 45 46 47 47 46 47 45 39 46 41\n",
      " 45 46 47 41 39 45 41 47 40 46 46 40 44 37 46 37 45 46 46 37 40 40 46 40\n",
      " 46 37 37 46 46 41 45 44 47 46 40 40 46 39 46 40 45 40 47 46 46 47 39 41\n",
      " 47 37 40 46 46 41 47 41 40 41 44 40 41 46 40 44 39 37 37 37 47 46 46 44\n",
      " 46 40 37 46 37 37 37 46 46 40 40 39 45 44 46 37 44 46 46 41 41 47 45 46\n",
      " 45 41 40 41 45 46 41 37 46 37 41 44 47 46 46 46 46 40 45 40 39 46 37 44\n",
      " 37 45 41 46 47 40 39 47 39 46 37 40 41 41 46 46 40 40 37 40 47 40 44 47\n",
      " 37 40 40 46 37 37 40 46 46 40 40 40 41 40 41 41 37 37 46 45 46 47 37 40\n",
      " 46 47 39 41 37 46 45 47 46 46 44 40 46 45 37 37 46 46 46 40 46 40 40 45\n",
      " 37 40 46 46 40 40 41 44 40 46 47 44 46 46 40 41 47 39 41 37 47 46 37 37\n",
      " 37 47 41 46 41 46 40 46 37 46 39 46 40 46 40 45 46 46 37 44 39 46 46 46\n",
      " 37 40 47 45 46 46 37 46 46 44 44 40 47 46 45 40 44 41 46 37 47 46 46 37\n",
      " 41 37 40 37 41 40 46 37 40 47 40 37 46 46 47 46 46 40 37 46 40 46 37 41\n",
      " 39 41 39 46 44 47 46 46 46 47 37 46 47 46 44 37 47 46 40 41 39 47 46 46\n",
      " 46 46 45 45 47 44 39 40 40 40 37 45 37 46]\n",
      "0.053003533568904596\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -103       0.00      0.00      0.00         2\n",
      "         -54       0.00      0.00      0.00         3\n",
      "          23       0.00      0.00      0.00         1\n",
      "          24       0.00      0.00      0.00         3\n",
      "          25       0.00      0.00      0.00         3\n",
      "          28       0.00      0.00      0.00         6\n",
      "          29       0.00      0.00      0.00        11\n",
      "          30       0.00      0.00      0.00         4\n",
      "          31       0.00      0.00      0.00        16\n",
      "          32       0.00      0.00      0.00        11\n",
      "          33       0.00      0.00      0.00        16\n",
      "          34       0.00      0.00      0.00        16\n",
      "          35       0.00      0.00      0.00        17\n",
      "          36       0.00      0.00      0.00        20\n",
      "          37       0.06      0.33      0.10        15\n",
      "          38       0.00      0.00      0.00        32\n",
      "          39       0.04      0.04      0.04        26\n",
      "          40       0.01      0.04      0.02        26\n",
      "          41       0.04      0.07      0.05        28\n",
      "          43       0.00      0.00      0.00        21\n",
      "          44       0.07      0.09      0.08        32\n",
      "          45       0.07      0.10      0.08        31\n",
      "          46       0.06      0.38      0.11        32\n",
      "          47       0.06      0.10      0.07        30\n",
      "          48       0.00      0.00      0.00        34\n",
      "          49       0.00      0.00      0.00        29\n",
      "          50       0.00      0.00      0.00        18\n",
      "          51       0.00      0.00      0.00        17\n",
      "          52       0.00      0.00      0.00        12\n",
      "          53       0.00      0.00      0.00         5\n",
      "          54       0.00      0.00      0.00         9\n",
      "          55       0.00      0.00      0.00         5\n",
      "          56       0.00      0.00      0.00         4\n",
      "          58       0.00      0.00      0.00         1\n",
      "          60       0.00      0.00      0.00        30\n",
      "\n",
      "    accuracy                           0.05       566\n",
      "   macro avg       0.01      0.03      0.02       566\n",
      "weighted avg       0.02      0.05      0.03       566\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc=SVC(kernel=\"linear\",C=2)\n",
    "model=svc.fit(x_train,y_train)\n",
    "y_predict1=model.predict(x_test)\n",
    "print(y_predict1)\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "\n",
    "\n",
    "ac=accuracy_score(y_test,y_predict1)\n",
    "print(ac)\n",
    "\n",
    "cm=confusion_matrix(y_test,y_predict1)\n",
    "print(cm)\n",
    "\n",
    "cr=classification_report(y_test,y_predict1)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['NAIVE', GaussianNB(priors=None, var_smoothing=1e-09)], ['SVM', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)], ['DECISION', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')], ['RAND', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)], ['KNN', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')]]\n",
      "accuracy without scaler NAIVE 0.021274003804809215\n",
      "accuracy without scaler SVM 0.07651229458694161\n",
      "accuracy without scaler DECISION 0.050970527009222964\n",
      "accuracy without scaler RAND 0.0726627881053944\n",
      "accuracy without scaler KNN 0.06258085357529258\n",
      "accuracy with scaler KNN 0.05138573851593018\n",
      "accuracy with scaler NAIVE 0.021274003804809215\n",
      "accuracy with scaler SVM 0.07982218502895941\n",
      "accuracy with scaler RAND 0.06195091979239473\n",
      "accuracy with scaler DECISION 0.05238567427430011\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"E:\\DSTUTORIALS\\Drug-consumers project\\durg alcohol.csv\")\n",
    "#print(df)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "m=LabelEncoder()\n",
    "df[\"Gender\"]=m.fit_transform(df[\"Gender\"])\n",
    "df[\"Country\"]=m.fit_transform(df[\"Country\"])\n",
    "df[\"Ethnicity\"]=m.fit_transform(df[\"Ethnicity\"])\n",
    "df[\"Alcohol\"]=m.fit_transform(df[\"Alcohol\"])\n",
    "df[\"Age\"]=m.fit_transform(df[\"Age\"])\n",
    "df[\"Impulsive\"]=m.fit_transform(df[\"Impulsive\"])\n",
    "\n",
    "\n",
    "n=df[\"Nscore\"]\n",
    "e=df[\"Escore\"]\n",
    "o=df[\"Oscore\"]\n",
    "a=df[\"Ascore\"]\n",
    "c=df[\"Cscore\"]\n",
    "i=df[\"Impulsive\"]\n",
    "ss=df[\"SS\"]\n",
    "x=df.drop([\"Nscore\",\"Escore\",\"Oscore\",\"Ascore\",\"Cscore\",\"Impulsive\",\"SS\"],axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,n,test_size=0.3)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,e,test_size=0.3)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,o,test_size=0.3)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,a,test_size=0.3)\n",
    "#x_train,x_test,y_train,y_test=train_test_split(x,c,test_size=0.3)\n",
    "#x_train,x_test,y_train,y_test=train_test_split(x,i,test_size=0.3)\n",
    "#x_train,x_test,y_train,y_test=train_test_split(x,ss,test_size=0.3)\n",
    "\n",
    "'''\n",
    "x=[n,e,o,a,c,i,ss]\n",
    "for i in f:\n",
    "    x_train,x_test,y_train,y_test=train_test_split(x,i,test_size=0.3)\n",
    "'''\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "algname=[]\n",
    "svmname=[\"SVM\",SVC()]\n",
    "decname=[\"DECISION\",DecisionTreeClassifier()]\n",
    "randname=[\"RAND\",RandomForestClassifier(n_estimators=10)]\n",
    "naviename=[\"NAIVE\",GaussianNB()]\n",
    "neighbname=[\"KNN\",KNeighborsClassifier()]\n",
    "algname.append(naviename)\n",
    "algname.append(svmname)\n",
    "algname.append(decname)\n",
    "algname.append(randname)\n",
    "algname.append(neighbname)\n",
    "print(algname)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "names=[]\n",
    "results=[]\n",
    "for name, models in algname:\n",
    "    kfold=KFold(n_splits=30)\n",
    "    c_results=cross_val_score(models,x_train,y_train,cv=10,scoring=\"accuracy\")\n",
    "    names.append(name)\n",
    "    results.append(c_results.mean())\n",
    "    print(\"accuracy without scaler\",name,c_results.mean())\n",
    "\n",
    "    \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "pipelines=[]\n",
    "pipelines.append((\"KNN\",Pipeline([(\"scaler\",StandardScaler()),(\"KNN\",KNeighborsClassifier())])))\n",
    "pipelines.append((\"NAIVE\",Pipeline([(\"scaler\",StandardScaler()),(\"naive\",GaussianNB())])))\n",
    "pipelines.append((\"SVM\",Pipeline([(\"scaler\",StandardScaler()),(\"SVC\",SVC())])))\n",
    "pipelines.append((\"RAND\",Pipeline([(\"scaler\",StandardScaler()),(\"Rand\",RandomForestClassifier())])))\n",
    "pipelines.append((\"DECISION\",Pipeline([(\"scaler\",StandardScaler()),(\"DECISION\",DecisionTreeClassifier())])))\n",
    "names=[]\n",
    "results=[]\n",
    "for name, model in pipelines:\n",
    "    kfold=KFold(n_splits=30)\n",
    "    c_results=cross_val_score(model,x_train,y_train,cv=10,scoring=\"accuracy\")\n",
    "    names.append(name)\n",
    "    results.append(c_results.mean())\n",
    "    print(\"accuracy with scaler\",name,c_results.mean())\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36 48 47 36 36 48 48 36 36 47 44 36 48 48 36 48 48 36 48 36 36 36 36 36\n",
      " 36 36 36 48 36 36 36 36 47 48 48 36 36 36 36 48 36 48 48 48 48 36 48 36\n",
      " 36 48 47 47 48 47 47 36 44 36 36 47 48 36 48 36 36 48 36 36 36 36 36 48\n",
      " 48 48 47 36 36 36 48 47 47 47 36 36 36 36 47 36 47 36 36 36 48 47 36 36\n",
      " 48 36 36 36 36 48 36 48 48 36 36 36 47 44 47 47 48 48 36 36 36 36 36 36\n",
      " 36 36 47 47 47 47 48 48 48 48 47 36 44 48 36 36 36 36 47 36 47 48 47 47\n",
      " 47 36 36 36 36 36 36 47 36 48 47 36 47 48 36 36 36 36 36 36 47 36 47 36\n",
      " 48 47 36 47 47 47 48 48 47 48 47 48 36 36 47 36 44 47 48 47 36 47 36 47\n",
      " 36 48 36 36 48 48 36 47 47 48 36 36 47 36 47 44 36 36 36 36 36 36 36 48\n",
      " 36 48 36 36 48 36 47 48 48 47 48 36 36 36 47 48 47 36 48 36 48 48 36 36\n",
      " 36 36 48 36 36 36 47 36 48 47 36 47 48 36 36 48 48 36 48 36 48 47 36 47\n",
      " 36 47 48 36 36 47 36 36 48 47 36 36 36 47 36 36 47 36 44 36 36 47 48 44\n",
      " 36 36 36 48 36 36 48 36 48 47 47 47 36 48 36 36 36 47 36 48 36 36 36 48\n",
      " 48 48 36 36 36 47 48 44 47 48 47 36 47 36 36 47 48 36 48 36 36 36 36 36\n",
      " 48 48 48 47 47 36 36 47 36 48 47 36 36 47 47 36 47 36 36 36 36 36 48 36\n",
      " 48 36 47 36 36 36 36 47 47 36 47 36 36 48 36 48 36 36 48 36 48 47 36 36\n",
      " 36 48 36 47 48 48 47 36 48 36 47 36 48 36 48 36 47 36 47 47 47 36 48 48\n",
      " 36 36 48 36 48 47 48 48 36 36 47 44 36 36 48 36 36 48 47 36 47 47 48 36\n",
      " 47 36 36 36 36 47 47 47 36 36 36 48 36 48 48 47 36 36 48 36 36 36 48 47\n",
      " 36 48 47 48 36 36 47 48 36 36 47 36 36 36 48 48 36 36 36 47 48 36 48 48\n",
      " 47 48 36 47 48 48 47 47 36 36 47 36 48 48 48 36 36 36 44 36 48 48 36 36\n",
      " 36 36 48 36 48 36 48 36 48 36 47 48 48 47 47 36 48 36 36 36 48 47 47 36\n",
      " 48 36 48 36 48 47 48 36 36 48 47 36 36 36 48 36 36 48 44 36 36 44 36 36\n",
      " 47 47 47 47 36 36 47 36 48 47 47 25 47 47]\n",
      "0.10424028268551237\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0  0  0  2  8  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  1  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  1  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  2  1  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  6  0  0  0  0  0  0  0  0  1  1  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0  2  1  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  3  4  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 26  0  0  0  0  0  2  0  0 10 14  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 15  0  0  0  0  0  0  0  0  4  4  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 30  0  0  0  0  0  0  0  0  6  6  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  1  0  0  8  5  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 19  0  0  0  0  0  2  0  0  5  4  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  2  0  0  9  7  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 18  0  0  0  0  0  1  0  0 10  9  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 15  0  0  0  0  0  0  0  0 11  9  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  8  8  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0  0 26  0  0  0  0  0  0  0  0 14 12  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 22  0  0  0  0  0  2  0  0 11 18  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  5  0  0  0  0  0  1  0  0  7 12  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  1  0  0  0  6  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  8  5  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  1  1  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  1  2  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  1  0  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  2  2  0  0\n",
      "   0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  2  0  0\n",
      "   0  0  0  0  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         -48       0.00      0.00      0.00        22\n",
      "          18       0.00      0.00      0.00         3\n",
      "          25       0.00      0.00      0.00         0\n",
      "          26       0.00      0.00      0.00         1\n",
      "          27       0.00      0.00      0.00         3\n",
      "          30       0.00      0.00      0.00         4\n",
      "          31       0.00      0.00      0.00         5\n",
      "          32       0.00      0.00      0.00         8\n",
      "          33       0.00      0.00      0.00         7\n",
      "          34       0.00      0.00      0.00        10\n",
      "          35       0.00      0.00      0.00        15\n",
      "          36       0.09      0.50      0.16        52\n",
      "          37       0.00      0.00      0.00        23\n",
      "          39       0.00      0.00      0.00        42\n",
      "          40       0.00      0.00      0.00        34\n",
      "          41       0.00      0.00      0.00        30\n",
      "          43       0.00      0.00      0.00        31\n",
      "          44       0.08      0.03      0.04        38\n",
      "          45       0.00      0.00      0.00        35\n",
      "          46       0.00      0.00      0.00        26\n",
      "          47       0.11      0.26      0.16        53\n",
      "          48       0.12      0.34      0.18        53\n",
      "          49       0.00      0.00      0.00        25\n",
      "          52       0.00      0.00      0.00         9\n",
      "          53       0.00      0.00      0.00        14\n",
      "          55       0.00      0.00      0.00         3\n",
      "          56       0.00      0.00      0.00         4\n",
      "          57       0.00      0.00      0.00         3\n",
      "          58       0.00      0.00      0.00         2\n",
      "          61       0.00      0.00      0.00         7\n",
      "          71       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.10       566\n",
      "   macro avg       0.01      0.04      0.02       566\n",
      "weighted avg       0.04      0.10      0.05       566\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc=SVC(kernel=\"linear\",C=2)\n",
    "model=svc.fit(x_train,y_train)\n",
    "y_predict1=model.predict(x_test)\n",
    "print(y_predict1)\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "\n",
    "\n",
    "ac=accuracy_score(y_test,y_predict1)\n",
    "print(ac)\n",
    "\n",
    "cm=confusion_matrix(y_test,y_predict1)\n",
    "print(cm)\n",
    "\n",
    "cr=classification_report(y_test,y_predict1)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['NAIVE', GaussianNB(priors=None, var_smoothing=1e-09)], ['SVM', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)], ['DECISION', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')], ['RAND', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)], ['KNN', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')]]\n",
      "accuracy without scaler NAIVE 0.012136586015692119\n",
      "accuracy without scaler SVM 0.08020794334332328\n",
      "accuracy without scaler DECISION 0.06717930929371663\n",
      "accuracy without scaler RAND 0.0706526395471522\n",
      "accuracy without scaler KNN 0.06465900981310177\n",
      "accuracy with scaler KNN 0.06888783479012928\n",
      "accuracy with scaler NAIVE 0.012136586015692119\n",
      "accuracy with scaler SVM 0.08283975033389653\n",
      "accuracy with scaler RAND 0.07105258283314217\n",
      "accuracy with scaler DECISION 0.065018747783427\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"E:\\DSTUTORIALS\\Drug-consumers project\\durg alcohol.csv\")\n",
    "#print(df)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "m=LabelEncoder()\n",
    "df[\"Gender\"]=m.fit_transform(df[\"Gender\"])\n",
    "df[\"Country\"]=m.fit_transform(df[\"Country\"])\n",
    "df[\"Ethnicity\"]=m.fit_transform(df[\"Ethnicity\"])\n",
    "df[\"Alcohol\"]=m.fit_transform(df[\"Alcohol\"])\n",
    "df[\"Age\"]=m.fit_transform(df[\"Age\"])\n",
    "df[\"Impulsive\"]=m.fit_transform(df[\"Impulsive\"])\n",
    "\n",
    "\n",
    "n=df[\"Nscore\"]\n",
    "e=df[\"Escore\"]\n",
    "o=df[\"Oscore\"]\n",
    "a=df[\"Ascore\"]\n",
    "c=df[\"Cscore\"]\n",
    "i=df[\"Impulsive\"]\n",
    "ss=df[\"SS\"]\n",
    "x=df.drop([\"Nscore\",\"Escore\",\"Oscore\",\"Ascore\",\"Cscore\",\"Impulsive\",\"SS\"],axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,n,test_size=0.3)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,e,test_size=0.3)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,o,test_size=0.3)\n",
    "#x_train,x_test,y_train,y_test=train_test_split(x,a,test_size=0.3)\n",
    "#x_train,x_test,y_train,y_test=train_test_split(x,c,test_size=0.3)\n",
    "#x_train,x_test,y_train,y_test=train_test_split(x,i,test_size=0.3)\n",
    "#x_train,x_test,y_train,y_test=train_test_split(x,ss,test_size=0.3)\n",
    "\n",
    "'''\n",
    "x=[n,e,o,a,c,i,ss]\n",
    "for i in f:\n",
    "    x_train,x_test,y_train,y_test=train_test_split(x,i,test_size=0.3)\n",
    "'''\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "algname=[]\n",
    "svmname=[\"SVM\",SVC()]\n",
    "decname=[\"DECISION\",DecisionTreeClassifier()]\n",
    "randname=[\"RAND\",RandomForestClassifier(n_estimators=10)]\n",
    "naviename=[\"NAIVE\",GaussianNB()]\n",
    "neighbname=[\"KNN\",KNeighborsClassifier()]\n",
    "algname.append(naviename)\n",
    "algname.append(svmname)\n",
    "algname.append(decname)\n",
    "algname.append(randname)\n",
    "algname.append(neighbname)\n",
    "print(algname)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "names=[]\n",
    "results=[]\n",
    "for name, models in algname:\n",
    "    kfold=KFold(n_splits=30)\n",
    "    c_results=cross_val_score(models,x_train,y_train,cv=10,scoring=\"accuracy\")\n",
    "    names.append(name)\n",
    "    results.append(c_results.mean())\n",
    "    print(\"accuracy without scaler\",name,c_results.mean())\n",
    "\n",
    "    \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "pipelines=[]\n",
    "pipelines.append((\"KNN\",Pipeline([(\"scaler\",StandardScaler()),(\"KNN\",KNeighborsClassifier())])))\n",
    "pipelines.append((\"NAIVE\",Pipeline([(\"scaler\",StandardScaler()),(\"naive\",GaussianNB())])))\n",
    "pipelines.append((\"SVM\",Pipeline([(\"scaler\",StandardScaler()),(\"SVC\",SVC())])))\n",
    "pipelines.append((\"RAND\",Pipeline([(\"scaler\",StandardScaler()),(\"Rand\",RandomForestClassifier())])))\n",
    "pipelines.append((\"DECISION\",Pipeline([(\"scaler\",StandardScaler()),(\"DECISION\",DecisionTreeClassifier())])))\n",
    "names=[]\n",
    "results=[]\n",
    "for name, model in pipelines:\n",
    "    kfold=KFold(n_splits=30)\n",
    "    c_results=cross_val_score(model,x_train,y_train,cv=10,scoring=\"accuracy\")\n",
    "    names.append(name)\n",
    "    results.append(c_results.mean())\n",
    "    print(\"accuracy with scaler\",name,c_results.mean())\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43 43 43 48 43 43 48 43 43 43 43 43 43 43 43 43 43 46 43 43 43 43 43 43\n",
      " 43 48 43 43 43 43 48 43 43 46 46 48 43 43 43 43 43 43 43 43 43 43 43 43\n",
      " 48 43 43 48 47 43 46 43 43 43 48 43 43 48 48 48 43 43 43 43 43 43 43 48\n",
      " 43 48 43 43 43 43 44 43 48 43 43 43 43 43 43 48 43 43 43 48 43 43 43 48\n",
      " 43 43 43 43 43 43 43 43 43 43 43 44 43 48 43 43 43 43 48 46 48 43 48 43\n",
      " 48 48 43 43 48 43 43 48 43 43 43 43 43 43 44 43 43 43 43 48 44 43 43 48\n",
      " 43 43 43 43 43 43 43 43 43 43 48 48 43 48 43 43 43 43 48 43 43 48 48 43\n",
      " 43 43 43 43 43 43 43 43 43 43 43 43 43 43 48 43 43 43 43 43 43 48 43 43\n",
      " 47 43 43 48 43 43 48 48 43 43 43 43 43 48 46 43 43 43 48 43 48 48 46 43\n",
      " 43 43 43 43 43 43 48 48 43 48 43 43 43 43 48 43 43 43 43 43 43 43 43 43\n",
      " 43 48 48 43 43 43 43 43 43 43 43 46 48 43 43 43 43 43 43 43 43 43 43 43\n",
      " 48 43 43 43 48 43 46 43 43 43 43 43 43 43 43 46 43 46 43 43 43 43 43 43\n",
      " 43 48 44 43 43 43 46 48 43 43 43 43 43 46 48 46 43 43 43 43 43 46 43 43\n",
      " 43 43 43 48 43 43 43 43 43 48 43 48 43 46 43 43 43 43 43 43 43 43 43 43\n",
      " 48 43 48 43 43 46 43 48 48 48 46 48 43 43 43 43 43 43 48 43 43 48 43 43\n",
      " 43 48 48 48 43 43 43 43 46 48 43 48 43 43 43 48 43 43 43 48 43 43 43 43\n",
      " 43 43 43 48 48 48 43 43 43 48 43 43 48 43 43 43 43 43 43 48 43 43 43 43\n",
      " 43 43 43 43 43 43 43 43 43 48 43 43 48 43 48 43 43 43 43 43 48 43 43 43\n",
      " 48 43 43 43 43 48 48 43 43 43 43 43 43 48 43 48 43 43 48 43 48 43 43 48\n",
      " 48 43 44 48 48 48 43 43 48 43 43 48 48 48 43 43 43 43 43 48 43 43 48 43\n",
      " 48 48 43 43 43 43 48 43 43 43 43 43 43 48 43 43 43 48 48 48 48 43 43 43\n",
      " 43 43 48 43 43 43 43 48 43 44 43 48 43 48 43 43 43 48 46 43 43 43 43 48\n",
      " 43 43 43 43 43 43 43 43 43 48 43 43 43 43 48 43 43 43 43 43 43 43 43 43\n",
      " 43 48 44 43 48 43 48 43 43 48 43 43 43 43]\n",
      "0.1166077738515901\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         -60       0.00      0.00      0.00         2\n",
      "         -56       0.00      0.00      0.00         1\n",
      "          23       0.00      0.00      0.00         2\n",
      "          29       0.00      0.00      0.00         3\n",
      "          31       0.00      0.00      0.00         4\n",
      "          32       0.00      0.00      0.00         6\n",
      "          33       0.00      0.00      0.00         6\n",
      "          34       0.00      0.00      0.00         9\n",
      "          35       0.00      0.00      0.00         6\n",
      "          36       0.00      0.00      0.00        15\n",
      "          37       0.00      0.00      0.00        13\n",
      "          38       0.00      0.00      0.00        19\n",
      "          39       0.00      0.00      0.00        19\n",
      "          40       0.00      0.00      0.00        23\n",
      "          41       0.00      0.00      0.00        18\n",
      "          43       0.12      0.90      0.22        58\n",
      "          44       0.00      0.00      0.00        18\n",
      "          45       0.00      0.00      0.00        30\n",
      "          46       0.30      0.12      0.17        50\n",
      "          47       0.00      0.00      0.00        34\n",
      "          48       0.07      0.22      0.10        36\n",
      "          49       0.00      0.00      0.00        24\n",
      "          50       0.00      0.00      0.00        26\n",
      "          51       0.00      0.00      0.00        29\n",
      "          52       0.00      0.00      0.00        26\n",
      "          53       0.00      0.00      0.00        24\n",
      "          54       0.00      0.00      0.00        19\n",
      "          55       0.00      0.00      0.00        17\n",
      "          56       0.00      0.00      0.00         6\n",
      "          57       0.00      0.00      0.00        12\n",
      "          58       0.00      0.00      0.00         7\n",
      "          59       0.00      0.00      0.00         2\n",
      "          60       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.12       566\n",
      "   macro avg       0.01      0.04      0.01       566\n",
      "weighted avg       0.04      0.12      0.04       566\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc=SVC(kernel=\"linear\",C=2)\n",
    "model=svc.fit(x_train,y_train)\n",
    "y_predict1=model.predict(x_test)\n",
    "print(y_predict1)\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "\n",
    "\n",
    "ac=accuracy_score(y_test,y_predict1)\n",
    "print(ac)\n",
    "\n",
    "cm=confusion_matrix(y_test,y_predict1)\n",
    "print(cm)\n",
    "\n",
    "cr=classification_report(y_test,y_predict1)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['NAIVE', GaussianNB(priors=None, var_smoothing=1e-09)], ['SVM', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)], ['DECISION', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')], ['RAND', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)], ['KNN', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')]]\n",
      "accuracy without scaler NAIVE 0.02379383423176267\n",
      "accuracy without scaler SVM 0.09607582772768378\n",
      "accuracy without scaler DECISION 0.08083199252588445\n",
      "accuracy without scaler RAND 0.07893604256120841\n",
      "accuracy without scaler KNN 0.05091068788798013\n",
      "accuracy with scaler KNN 0.0512002145356515\n",
      "accuracy with scaler NAIVE 0.02379383423176267\n",
      "accuracy with scaler SVM 0.09052258830439854\n",
      "accuracy with scaler RAND 0.07470518658031626\n",
      "accuracy with scaler DECISION 0.08160203962050183\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"E:\\DSTUTORIALS\\Drug-consumers project\\durg alcohol.csv\")\n",
    "#print(df)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "m=LabelEncoder()\n",
    "df[\"Gender\"]=m.fit_transform(df[\"Gender\"])\n",
    "df[\"Country\"]=m.fit_transform(df[\"Country\"])\n",
    "df[\"Ethnicity\"]=m.fit_transform(df[\"Ethnicity\"])\n",
    "df[\"Alcohol\"]=m.fit_transform(df[\"Alcohol\"])\n",
    "df[\"Age\"]=m.fit_transform(df[\"Age\"])\n",
    "df[\"Impulsive\"]=m.fit_transform(df[\"Impulsive\"])\n",
    "\n",
    "\n",
    "n=df[\"Nscore\"]\n",
    "e=df[\"Escore\"]\n",
    "o=df[\"Oscore\"]\n",
    "a=df[\"Ascore\"]\n",
    "c=df[\"Cscore\"]\n",
    "i=df[\"Impulsive\"]\n",
    "ss=df[\"SS\"]\n",
    "x=df.drop([\"Nscore\",\"Escore\",\"Oscore\",\"Ascore\",\"Cscore\",\"Impulsive\",\"SS\"],axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,n,test_size=0.3)\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,e,test_size=0.3)\n",
    "#x_train,x_test,y_train,y_test=train_test_split(x,o,test_size=0.3)\n",
    "#x_train,x_test,y_train,y_test=train_test_split(x,a,test_size=0.3)\n",
    "#_train,x_test,y_train,y_test=train_test_split(x,c,test_size=0.3)\n",
    "#x_train,x_test,y_train,y_test=train_test_split(x,i,test_size=0.3)\n",
    "#x_train,x_test,y_train,y_test=train_test_split(x,ss,test_size=0.3)\n",
    "\n",
    "'''\n",
    "x=[n,e,o,a,c,i,ss]\n",
    "for i in f:\n",
    "    x_train,x_test,y_train,y_test=train_test_split(x,i,test_size=0.3)\n",
    "'''\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "algname=[]\n",
    "svmname=[\"SVM\",SVC()]\n",
    "decname=[\"DECISION\",DecisionTreeClassifier()]\n",
    "randname=[\"RAND\",RandomForestClassifier(n_estimators=10)]\n",
    "naviename=[\"NAIVE\",GaussianNB()]\n",
    "neighbname=[\"KNN\",KNeighborsClassifier()]\n",
    "algname.append(naviename)\n",
    "algname.append(svmname)\n",
    "algname.append(decname)\n",
    "algname.append(randname)\n",
    "algname.append(neighbname)\n",
    "print(algname)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "names=[]\n",
    "results=[]\n",
    "for name, models in algname:\n",
    "    kfold=KFold(n_splits=30)\n",
    "    c_results=cross_val_score(models,x_train,y_train,cv=10,scoring=\"accuracy\")\n",
    "    names.append(name)\n",
    "    results.append(c_results.mean())\n",
    "    print(\"accuracy without scaler\",name,c_results.mean())\n",
    "\n",
    "    \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "pipelines=[]\n",
    "pipelines.append((\"KNN\",Pipeline([(\"scaler\",StandardScaler()),(\"KNN\",KNeighborsClassifier())])))\n",
    "pipelines.append((\"NAIVE\",Pipeline([(\"scaler\",StandardScaler()),(\"naive\",GaussianNB())])))\n",
    "pipelines.append((\"SVM\",Pipeline([(\"scaler\",StandardScaler()),(\"SVC\",SVC())])))\n",
    "pipelines.append((\"RAND\",Pipeline([(\"scaler\",StandardScaler()),(\"Rand\",RandomForestClassifier())])))\n",
    "pipelines.append((\"DECISION\",Pipeline([(\"scaler\",StandardScaler()),(\"DECISION\",DecisionTreeClassifier())])))\n",
    "names=[]\n",
    "results=[]\n",
    "for name, model in pipelines:\n",
    "    kfold=KFold(n_splits=30)\n",
    "    c_results=cross_val_score(model,x_train,y_train,cv=10,scoring=\"accuracy\")\n",
    "    names.append(name)\n",
    "    results.append(c_results.mean())\n",
    "    print(\"accuracy with scaler\",name,c_results.mean())\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36 36 43 43 41 43 36 36 36 36 43 36 36 36 43 36 36 36 43 43 36 36 43 36\n",
      " 43 43 36 36 36 36 43 43 36 43 43 36 36 43 43 43 36 43 43 36 36 43 36 36\n",
      " 36 43 36 43 43 36 36 43 36 36 43 43 43 36 43 36 36 36 36 43 36 36 36 43\n",
      " 43 43 36 36 43 43 43 41 41 43 36 36 36 36 36 43 36 43 43 43 36 43 36 43\n",
      " 41 36 36 36 36 36 36 36 36 36 36 36 43 36 36 36 41 36 43 43 36 36 36 36\n",
      " 43 43 36 36 36 41 43 41 41 43 36 36 43 43 36 36 36 43 36 36 36 43 41 36\n",
      " 43 36 43 43 43 36 36 36 41 43 36 43 43 36 36 36 36 43 36 36 43 36 36 36\n",
      " 43 43 36 36 36 36 36 43 36 36 43 43 36 43 43 36 43 36 43 36 36 36 36 41\n",
      " 36 36 36 43 36 41 36 43 36 36 43 36 36 36 43 43 36 43 36 43 36 36 43 36\n",
      " 36 36 36 36 43 36 43 43 43 43 43 43 36 41 43 43 36 36 43 43 43 43 36 43\n",
      " 36 43 43 36 36 43 43 43 36 36 36 36 43 36 41 43 36 43 43 36 36 43 36 36\n",
      " 36 43 36 36 43 36 36 36 43 43 41 36 43 41 43 36 36 43 36 43 41 36 43 36\n",
      " 43 43 36 43 43 43 36 36 43 43 43 36 36 36 36 36 43 43 43 41 36 43 43 36\n",
      " 43 36 43 36 43 43 36 36 43 36 36 36 36 36 36 43 43 43 36 43 43 36 41 43\n",
      " 36 43 43 43 36 43 36 43 41 41 43 36 36 41 36 43 43 36 43 36 36 43 36 36\n",
      " 43 43 43 36 36 43 36 43 43 43 43 36 43 43 36 36 36 43 36 43 36 43 43 36\n",
      " 43 41 36 36 36 36 36 36 36 36 41 36 36 36 43 36 36 43 36 36 41 36 43 43\n",
      " 36 43 41 43 36 36 36 36 36 43 36 43 36 43 36 36 43 36 43 43 36 36 43 36\n",
      " 43 41 36 36 41 43 43 36 43 36 36 43 43 43 36 36 36 36 41 36 36 36 36 36\n",
      " 36 36 36 43 36 43 36 36 41 36 43 36 43 36 36 36 36 43 36 36 36 43 43 36\n",
      " 43 43 43 43 36 36 36 43 43 36 36 43 43 36 36 36 36 43 43 43 36 36 36 36\n",
      " 36 36 36 43 41 43 36 36 43 43 43 36 36 36 43 36 43 36 43 43 36 36 36 36\n",
      " 36 36 43 43 36 43 36 36 36 36 36 43 43 43 36 36 43 36 36 43 36 36 43 43\n",
      " 36 36 43 41 43 36 41 43 41 43 43 43 41 43]\n",
      "0.07420494699646643\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -103       0.00      0.00      0.00         9\n",
      "         -54       0.00      0.00      0.00         3\n",
      "          19       0.00      0.00      0.00         2\n",
      "          23       0.00      0.00      0.00         1\n",
      "          24       0.00      0.00      0.00         2\n",
      "          25       0.00      0.00      0.00         2\n",
      "          27       0.00      0.00      0.00         7\n",
      "          28       0.00      0.00      0.00         8\n",
      "          29       0.00      0.00      0.00        11\n",
      "          30       0.00      0.00      0.00        10\n",
      "          31       0.00      0.00      0.00        15\n",
      "          32       0.00      0.00      0.00        17\n",
      "          34       0.00      0.00      0.00        25\n",
      "          35       0.00      0.00      0.00        17\n",
      "          36       0.09      0.51      0.15        53\n",
      "          37       0.00      0.00      0.00        23\n",
      "          38       0.00      0.00      0.00        27\n",
      "          40       0.00      0.00      0.00        44\n",
      "          41       0.09      0.08      0.08        37\n",
      "          42       0.00      0.00      0.00        42\n",
      "          43       0.05      0.24      0.09        49\n",
      "          44       0.00      0.00      0.00        38\n",
      "          45       0.00      0.00      0.00        34\n",
      "          46       0.00      0.00      0.00        15\n",
      "          47       0.00      0.00      0.00        21\n",
      "          48       0.00      0.00      0.00        10\n",
      "          49       0.00      0.00      0.00        12\n",
      "          50       0.00      0.00      0.00         4\n",
      "          51       0.00      0.00      0.00         8\n",
      "          52       0.00      0.00      0.00         5\n",
      "          53       0.00      0.00      0.00         5\n",
      "          54       0.00      0.00      0.00         4\n",
      "          55       0.00      0.00      0.00         4\n",
      "          56       0.00      0.00      0.00         1\n",
      "          58       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.07       566\n",
      "   macro avg       0.01      0.02      0.01       566\n",
      "weighted avg       0.02      0.07      0.03       566\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc=SVC(kernel=\"linear\",C=2)\n",
    "model=svc.fit(x_train,y_train)\n",
    "y_predict1=model.predict(x_test)\n",
    "print(y_predict1)\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "\n",
    "\n",
    "ac=accuracy_score(y_test,y_predict1)\n",
    "print(ac)\n",
    "\n",
    "cm=confusion_matrix(y_test,y_predict1)\n",
    "print(cm)\n",
    "\n",
    "cr=classification_report(y_test,y_predict1)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['NAIVE', GaussianNB(priors=None, var_smoothing=1e-09)], ['SVM', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
      "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
      "    shrinking=True, tol=0.001, verbose=False)], ['DECISION', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='best')], ['RAND', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)], ['KNN', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "                     weights='uniform')]]\n",
      "accuracy without scaler NAIVE 0.007893929671301933\n",
      "accuracy without scaler SVM 0.05077874447656464\n",
      "accuracy without scaler DECISION 0.026035952962775933\n",
      "accuracy without scaler RAND 0.026192214083390942\n",
      "accuracy without scaler KNN 0.029017124744995897\n",
      "accuracy with scaler KNN 0.02854506130488223\n",
      "accuracy with scaler NAIVE 0.007893929671301933\n",
      "accuracy with scaler SVM 0.039225948368053105\n",
      "accuracy with scaler RAND 0.027854063677913866\n",
      "accuracy with scaler DECISION 0.024275818944368064\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"E:\\DSTUTORIALS\\Drug-consumers project\\durg alcohol.csv\")\n",
    "#print(df)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "m=LabelEncoder()\n",
    "df[\"Gender\"]=m.fit_transform(df[\"Gender\"])\n",
    "df[\"Country\"]=m.fit_transform(df[\"Country\"])\n",
    "df[\"Ethnicity\"]=m.fit_transform(df[\"Ethnicity\"])\n",
    "df[\"Alcohol\"]=m.fit_transform(df[\"Alcohol\"])\n",
    "df[\"Age\"]=m.fit_transform(df[\"Age\"])\n",
    "df[\"Impulsive\"]=m.fit_transform(df[\"Impulsive\"])\n",
    "\n",
    "\n",
    "n=df[\"Nscore\"]\n",
    "e=df[\"Escore\"]\n",
    "o=df[\"Oscore\"]\n",
    "a=df[\"Ascore\"]\n",
    "c=df[\"Cscore\"]\n",
    "i=df[\"Impulsive\"]\n",
    "ss=df[\"SS\"]\n",
    "x=df.drop([\"Nscore\",\"Escore\",\"Oscore\",\"Ascore\",\"Cscore\",\"Impulsive\",\"SS\"],axis=1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,n,test_size=0.3)\n",
    "#x_train,x_test,y_train,y_test=train_test_split(x,e,test_size=0.3)\n",
    "#x_train,x_test,y_train,y_test=train_test_split(x,o,test_size=0.3)\n",
    "#x_train,x_test,y_train,y_test=train_test_split(x,a,test_size=0.3)\n",
    "#x_train,x_test,y_train,y_test=train_test_split(x,c,test_size=0.3)\n",
    "#x_train,x_test,y_train,y_test=train_test_split(x,i,test_size=0.3)\n",
    "#x_train,x_test,y_train,y_test=train_test_split(x,ss,test_size=0.3)\n",
    "\n",
    "'''\n",
    "x=[n,e,o,a,c,i,ss]\n",
    "for i in f:\n",
    "    x_train,x_test,y_train,y_test=train_test_split(x,i,test_size=0.3)\n",
    "'''\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "algname=[]\n",
    "svmname=[\"SVM\",SVC()]\n",
    "decname=[\"DECISION\",DecisionTreeClassifier()]\n",
    "randname=[\"RAND\",RandomForestClassifier(n_estimators=10)]\n",
    "naviename=[\"NAIVE\",GaussianNB()]\n",
    "neighbname=[\"KNN\",KNeighborsClassifier()]\n",
    "algname.append(naviename)\n",
    "algname.append(svmname)\n",
    "algname.append(decname)\n",
    "algname.append(randname)\n",
    "algname.append(neighbname)\n",
    "print(algname)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "names=[]\n",
    "results=[]\n",
    "for name, models in algname:\n",
    "    kfold=KFold(n_splits=30)\n",
    "    c_results=cross_val_score(models,x_train,y_train,cv=10,scoring=\"accuracy\")\n",
    "    names.append(name)\n",
    "    results.append(c_results.mean())\n",
    "    print(\"accuracy without scaler\",name,c_results.mean())\n",
    "\n",
    "    \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "pipelines=[]\n",
    "pipelines.append((\"KNN\",Pipeline([(\"scaler\",StandardScaler()),(\"KNN\",KNeighborsClassifier())])))\n",
    "pipelines.append((\"NAIVE\",Pipeline([(\"scaler\",StandardScaler()),(\"naive\",GaussianNB())])))\n",
    "pipelines.append((\"SVM\",Pipeline([(\"scaler\",StandardScaler()),(\"SVC\",SVC())])))\n",
    "pipelines.append((\"RAND\",Pipeline([(\"scaler\",StandardScaler()),(\"Rand\",RandomForestClassifier())])))\n",
    "pipelines.append((\"DECISION\",Pipeline([(\"scaler\",StandardScaler()),(\"DECISION\",DecisionTreeClassifier())])))\n",
    "names=[]\n",
    "results=[]\n",
    "for name, model in pipelines:\n",
    "    kfold=KFold(n_splits=30)\n",
    "    c_results=cross_val_score(model,x_train,y_train,cv=10,scoring=\"accuracy\")\n",
    "    names.append(name)\n",
    "    results.append(c_results.mean())\n",
    "    print(\"accuracy with scaler\",name,c_results.mean())\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34 42 32 32 29 40 32 32 36 39 33 28 34 43 39 34 39 25 34 32 41 25 34 39\n",
      " 34 41 48 34 41 28 40 27 34 34 34 40 36 41 29 43 32 40 40 34 34 36 42 28\n",
      " 39 34 39 39 27 28 39 34 41 32 36 34 32 27 41 37 25 28 32 41 36 41 32 39\n",
      " 32 41 30 39 26 34 28 34 34 40 34 39 41 36 34 41 34 36 28 27 41 34 28 32\n",
      " 34 29 28 33 32 41 32 41 34 34 36 39 32 36 34 28 34 25 28 34 28 27 32 32\n",
      " 37 41 27 32 32 28 39 36 34 39 41 34 43 36 28 32 34 32 39 36 37 39 41 29\n",
      " 43 36 41 42 41 39 39 41 31 32 34 41 29 42 28 28 39 34 32 36 41 28 32 41\n",
      " 40 34 48 39 36 36 39 28 33 39 25 34 39 41 40 34 34 29 42 34 41 34 27 39\n",
      " 27 40 36 27 43 34 32 32 41 34 36 27 28 39 32 39 34 34 41 36 41 43 34 41\n",
      " 32 34 28 26 39 34 36 41 34 34 48 29 34 34 36 36 36 27 39 28 39 34 42 34\n",
      " 34 28 36 34 32 36 34 28 40 32 41 28 34 41 36 27 33 34 43 34 41 39 34 36\n",
      " 34 31 31 28 28 34 40 41 39 32 42 36 41 39 34 29 32 40 34 40 27 34 32 32\n",
      " 28 28 39 28 32 37 41 32 39 34 42 40 33 36 29 42 34 34 41 34 34 39 41 42\n",
      " 25 39 31 34 27 28 41 27 37 36 34 34 36 32 27 27 42 28 41 41 34 34 36 34\n",
      " 34 40 43 39 39 40 39 34 34 41 36 28 34 34 28 41 34 34 26 41 34 34 39 39\n",
      " 39 28 27 39 36 36 41 41 41 32 28 48 40 34 34 39 32 39 34 36 34 29 34 41\n",
      " 37 28 36 36 33 34 41 34 28 29 34 25 41 41 30 39 42 39 41 39 34 34 32 41\n",
      " 34 33 34 34 34 40 32 36 34 32 33 34 28 34 32 33 27 27 41 28 34 34 34 41\n",
      " 34 32 40 25 36 34 36 36 28 26 40 34 29 40 34 40 40 34 28 34 34 28 39 28\n",
      " 27 28 29 39 28 39 37 27 41 34 41 37 36 39 36 41 25 34 29 41 32 34 42 34\n",
      " 32 33 34 32 34 40 32 39 34 41 36 34 43 41 31 28 34 32 34 39 33 41 39 34\n",
      " 34 33 34 36 36 36 33 33 34 39 41 34 36 25 39 34 34 34 42 41 28 39 34 34\n",
      " 28 28 39 28 32 36 41 34 33 40 29 41 36 39 39 29 41 28 28 34 41 25 41 34\n",
      " 32 39 39 28 28 34 37 32 34 40 34 34 39 34]\n",
      "0.04063604240282685\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          12       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       0.00      0.00      0.00         3\n",
      "          19       0.00      0.00      0.00         1\n",
      "          20       0.00      0.00      0.00        15\n",
      "          21       0.00      0.00      0.00         9\n",
      "          22       0.00      0.00      0.00         6\n",
      "          23       0.00      0.00      0.00        10\n",
      "          24       0.00      0.00      0.00        11\n",
      "          25       0.09      0.05      0.07        19\n",
      "          26       0.00      0.00      0.00        20\n",
      "          27       0.05      0.05      0.05        22\n",
      "          28       0.06      0.16      0.08        19\n",
      "          29       0.06      0.06      0.06        17\n",
      "          30       0.00      0.00      0.00        21\n",
      "          31       0.20      0.03      0.05        33\n",
      "          32       0.04      0.08      0.05        26\n",
      "          33       0.00      0.00      0.00        19\n",
      "          34       0.04      0.26      0.06        19\n",
      "          35       0.00      0.00      0.00        21\n",
      "          36       0.02      0.07      0.03        15\n",
      "          37       0.11      0.05      0.07        21\n",
      "          38       0.00      0.00      0.00        21\n",
      "          39       0.02      0.04      0.02        23\n",
      "          40       0.04      0.03      0.04        29\n",
      "          41       0.04      0.20      0.07        15\n",
      "          42       0.14      0.07      0.09        30\n",
      "          43       0.00      0.00      0.00         9\n",
      "          44       0.00      0.00      0.00        12\n",
      "          45       0.00      0.00      0.00        10\n",
      "          46       0.00      0.00      0.00        18\n",
      "          47       0.00      0.00      0.00         4\n",
      "          48       0.00      0.00      0.00        14\n",
      "          49       0.00      0.00      0.00        13\n",
      "          50       0.00      0.00      0.00         6\n",
      "          51       0.00      0.00      0.00         6\n",
      "          52       0.00      0.00      0.00         7\n",
      "          53       0.00      0.00      0.00         3\n",
      "          55       0.00      0.00      0.00         5\n",
      "          56       0.00      0.00      0.00         4\n",
      "          57       0.00      0.00      0.00         1\n",
      "          58       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.04       566\n",
      "   macro avg       0.02      0.02      0.02       566\n",
      "weighted avg       0.04      0.04      0.03       566\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc=SVC(kernel=\"linear\",C=2)\n",
    "model=svc.fit(x_train,y_train)\n",
    "y_predict1=model.predict(x_test)\n",
    "print(y_predict1)\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "\n",
    "\n",
    "ac=accuracy_score(y_test,y_predict1)\n",
    "print(ac)\n",
    "\n",
    "cm=confusion_matrix(y_test,y_predict1)\n",
    "print(cm)\n",
    "\n",
    "cr=classification_report(y_test,y_predict1)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FINALLY MY CONCLUSION IS ITS NEED SOME MORE DATA FOR BETTER ACCURACY.\n",
    "#F1-SCORE VALUE IS LESS THAN ALPHA VALUE SO ITS BAD PREDICTION"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
